{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸ¦„ðŸ¦„ðŸ¦„       ðŸ¦„ðŸ¦„ðŸ¦„     ðŸ¦„ðŸ¦„ðŸ¦„      ðŸ¦„ðŸ¦„ðŸ¦„      ðŸ¦„ðŸ¦„ðŸ¦„      ðŸ¦„ðŸ¦„ðŸ¦„     ðŸ¦„ðŸ¦„ðŸ¦„    ðŸ¦„ðŸ¦„ðŸ¦„    ðŸ¦„ðŸ¦„ðŸ¦„   ðŸ¦„ðŸ¦„ðŸ¦„    ðŸ¦„ðŸ¦„ðŸ¦„     ðŸ¦„ðŸ¦„ðŸ¦„ ðŸ¦„ðŸ¦„ðŸ¦„ ðŸ¦„ðŸ¦„ðŸ¦„ ðŸ¦„ðŸ¦„ðŸ¦„ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the ETL task for getting your UnicornðŸ¦„ Rental Bussiness to New heights. \n",
    "\n",
    "In this notebook, we will carry out following ETL Tasks:\n",
    "\n",
    "1. Download Data: Get the Data from prepopulated Aurora Database from your account.  \n",
    "2. Data Cleaning: Clean the data, add/delete/rename columns in the data downloaded in step 1.\n",
    "3. Data Upload: Upload these cleaned csv's to S3 bucket. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Downloadig Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In this task, we will: \n",
    "    1.1. Install Dependencies\n",
    "    1.2. Connect to database \n",
    "    1.3. Query database tables for the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Install Dependencies\n",
    "\n",
    "psycopg2 is a python package to set up connection with rds database which holds the data. As psycopg2 has multiple depencies which may conflict with other packages when installed using pip, we will installing this package using conda install. Conda install handles dependcies better given the numerous conda environments deployed by sagemaker studio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%conda install psycopg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Connect to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set up connection with database, we will need following database credentials. From your AWS console, look up hostname(endpoint), region and password. We will initialize all the credentials/params in the following cell. \n",
    "Following is an example: \n",
    " \n",
    "```\n",
    "host=\"gameday-aurora-postgres.cluster-cj8pr0iv1jkb.us-east-2.rds.amazonaws.com\"     <- db endpoint  (fetch it from aws console)\n",
    "PORT=\"5432\"                                                                         <- default\n",
    "USER=\"postgres\"                                                                     <- default\n",
    "DBNAME=\"postgres\"                                                                   <- DBName \n",
    "password = \"fn3t8ZgN06ABpSrT\"                                                       <- database password  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "host=\"gameday-aurora-postgres.cluster-ro-cj8pr0iv1jkb.us-east-2.rds.amazonaws.com\" \n",
    "PORT=\"5432\"\n",
    "USER=\"postgres\"\n",
    "DBNAME=\"postgres\"\n",
    "password = \"fn3t8Z6AMygN06ABpSrT\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Destination bucket to upload cleaned data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_s3Bucket = 'khobaib-test-bucket'   #<--- Look up your deployed stack and replace bucket name with yours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import python packages and set up connection using connect method of psycopg2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "conn = psycopg2.connect(host = host,database = DBNAME, user = USER,password = password)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Query database tables for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df=pd.read_sql(\"\"\"SELECT productkey, productsubcategorykey, listprice  FROM gameday.product\"\"\", conn) \n",
    "users_df=pd.read_sql(\"\"\"SELECT customerkey, gender,yearlyincome FROM gameday.customer \"\"\", conn)\n",
    "interactions_df=pd.read_sql(\"\"\"SELECT productkey, customerkey, orderdate FROM gameday.internetsales\"\"\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the original interactions as it will be referenced couple of time after cleaning\n",
    "interactions_df_orig = interactions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean `interactions_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# filter unique product keys\n",
    "unique_product_keys = set(items_df['productkey'].unique())  \n",
    "\n",
    "# filter interactions data rows where product key exists in unique product key\n",
    "interactions_df = interactions_df[interactions_df['productkey'].isin(unique_product_keys)]  \n",
    "\n",
    "#convert order datetime column datatype to pandas datetime data type\n",
    "interactions_df['OrderDate_datetime'] = pd.to_datetime(interactions_df['orderdate'])\n",
    "\n",
    "#add column TIMESTAMP which contains above OrderDate time converted in numpy int64 datatype\n",
    "interactions_df['TIMESTAMP'] = interactions_df.OrderDate_datetime.values.astype(np.int64) // 10 ** 9\n",
    " \n",
    "# column rename column 'productkey' to 'ITEM_ID' and column 'customerkey' to 'USER_ID'\n",
    "interactions_df = interactions_df.rename(columns={'productkey':'ITEM_ID', 'customerkey':'USER_ID'}) \n",
    "\n",
    "# select columns ITEM_ID, USER_ID and TIMESTAMP only from interactions dataframe and drop other columns. \n",
    "interactions_df = interactions_df[['ITEM_ID', 'USER_ID', 'TIMESTAMP']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets print how interactions_df dataframe looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>375.0</td>\n",
       "      <td>13464.0</td>\n",
       "      <td>1666656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>358.0</td>\n",
       "      <td>13011.0</td>\n",
       "      <td>1666656000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>356.0</td>\n",
       "      <td>13012.0</td>\n",
       "      <td>1666656000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ITEM_ID  USER_ID   TIMESTAMP\n",
       "0    375.0  13464.0  1666656000\n",
       "1    358.0  13011.0  1666656000\n",
       "2    356.0  13012.0  1666656000"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interactions_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save cleaned df to csv in local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os and pathlib to create directory locally\n",
    "import os\n",
    "from pathlib import Path \n",
    "\n",
    "# path where we want to store the cleaned interactions dataframe\n",
    "path = Path(\"./data/clean\")\n",
    "\n",
    "# create the directory structure if it doesnt exist\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# save the dataframe to a csv file named interactions.csv\n",
    "interactions_df.to_csv(os.path.join(path, 'interactions.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean `users_df` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter unique product keys\n",
    "unique_user_keys = set(interactions_df_orig['customerkey'].unique())\n",
    "\n",
    "# filter users data rows where product key exists in unique product key\n",
    "users_df = users_df[users_df['customerkey'].isin(unique_user_keys)]\n",
    "\n",
    "# column rename column customerkey to USER_ID, 'gender' to 'Gender', 'yearlyincome' to 'YearlyIncome\n",
    "users_df = users_df.rename(columns={'customerkey':'USER_ID', 'gender': 'Gender', 'yearlyincome': 'YearlyIncome'})\n",
    "\n",
    "# save users dataframe locally to users.csv file\n",
    "users_df.to_csv(os.path.join(path, 'users.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USER_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>YearlyIncome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11001</td>\n",
       "      <td>M</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11002</td>\n",
       "      <td>M</td>\n",
       "      <td>60000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11003</td>\n",
       "      <td>F</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USER_ID Gender  YearlyIncome\n",
       "0    11001      M       60000.0\n",
       "1    11002      M       60000.0\n",
       "2    11003      F       70000.0"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets print users_df dataframe to checkout cleaned version \n",
    "users_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean `items_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITEM_ID</th>\n",
       "      <th>ProductSubcategory</th>\n",
       "      <th>ListPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310</td>\n",
       "      <td>Road Cosmic Unicorn</td>\n",
       "      <td>3578.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>311</td>\n",
       "      <td>Road Cosmic Unicorn</td>\n",
       "      <td>3578.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>312</td>\n",
       "      <td>Road Cosmic Unicorn</td>\n",
       "      <td>3578.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ITEM_ID   ProductSubcategory  ListPrice\n",
       "0      310  Road Cosmic Unicorn    3578.27\n",
       "1      311  Road Cosmic Unicorn    3578.27\n",
       "2      312  Road Cosmic Unicorn    3578.27"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: there should be no mention of bikes. these values should come from the subcategory table. they are already transformed by Jose. Please consult with him about where to get them\n",
    "items_df = items_df[items_df['productsubcategorykey'] < 4]\n",
    "items_df['productsubcategorykey'] = items_df['productsubcategorykey'].replace({1: 'Mountain Cosmic Unicorn', 2: 'Road Cosmic Unicorn', 3: 'Touring Cosmic Unicorn'})\n",
    "items_df = items_df.rename(columns={'productkey':'ITEM_ID', 'productsubcategorykey':'ProductSubcategory', 'listprice': 'ListPrice'})\n",
    "\n",
    "items_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df.to_csv('./data/clean/items.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Upload data to S3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous steps, we cleaned the data and saved dataframe into a csv on our local disk. To use this data for training in personalize, lets save it into s3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload to s3 bucket\n",
    "import boto3\n",
    "boto3.Session().resource('s3').Bucket(dest_s3Bucket)\\\n",
    "        .Object('data/interactions.csv').upload_file('./data/clean/interactions.csv')\n",
    "\n",
    "#upload to s3 bucket\n",
    "import boto3\n",
    "boto3.Session().resource('s3').Bucket(dest_s3Bucket)\\\n",
    "        .Object('data/items.csv').upload_file('./data/clean/items.csv')\n",
    "\n",
    "#upload to s3 bucket\n",
    "import boto3\n",
    "boto3.Session().resource('s3').Bucket(dest_s3Bucket)\\\n",
    "        .Object('data/users.csv').upload_file('./data/clean/users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the cleaned csv files are on S3, we will be importing these into personlize engine for training in next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
